{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOFvz1xX9zSUcGfyiPglqjl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/neelkanthrawat/GNN-exercises/blob/main/Assignment_1_Neel's_attempt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "LgoPLanS-CL-"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy as sp\n",
        "import pandas as pd\n",
        "from typing import List"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### define a gaussian function in n_star dimn\n",
        "\n",
        "####"
      ],
      "metadata": {
        "id": "1JZb9EOS-K7r"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### define two dimensional gaussian distribution\n",
        "\n",
        "### this gaussian has the ability to infer (evaluate the probability at the given point)\n",
        "def gaussian_2d(x:np.array,mean:np.array,cov_mat:np.array):\n",
        "  '''\n",
        "  This model will evaluate the probabilty at the given x_vector.\n",
        "  Args:\n",
        "  1. x= np array of shape (1 X dimn_of_the_problem=2)\n",
        "  2. mean= np array of shape (1 X dimn_of_the_problem=2)\n",
        "  3.cov_mat= square np array of shape (dimn_of_the_prob=2)\n",
        "  '''\n",
        "  dimn=np.shape(x)[0]\n",
        "  # x=np.array(x).reshape((1,dimn))\n",
        "  # mean=np.array(mean).reshape((1,dimn))\n",
        "  # print(\"shape(x),shape(mean)\")\n",
        "  # print(np.shape(x), np.shape(mean))\n",
        "  # note that x is a row vector\n",
        "\n",
        "  inv_cov=np.linalg.inv(cov_mat)\n",
        "  x_minus_mu=x-mean\n",
        "\n",
        "  # argument for the exp\n",
        "  arg_for_expn=0.5*(x_minus_mu @ inv_cov @ np.transpose(x_minus_mu))[0,0]\n",
        "  det_cov=np.linalg.det(cov_mat)\n",
        "  # evaluating the prob\n",
        "  prob=np.exp(-arg_for_expn) * (1./(2*np.pi*np.sqrt(det_cov)))\n",
        "\n",
        "  return prob"
      ],
      "metadata": {
        "id": "GH3pUOYhAg5C"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x=np.array([[0.5,0.5]])\n",
        "mean=np.array([[1,1]])\n",
        "cov_mat=np.array([[0.3,0.22],[0.22,0.8]])\n",
        "check=gaussian_2d(x,mean,cov_mat)\n",
        "print(check)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F0Gj7DOuJZ9P",
        "outputId": "216d33ec-c6ee-4054-91ed-548727274066"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape(x),shape(mean)\n",
            "(1, 2) (1, 2)\n",
            "0.2363860723405543\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### I have a 2D gaussian model at my disposal for the time being. now I need to check how to train it to fit the given dataset"
      ],
      "metadata": {
        "id": "KrFx9MwzMGWe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### fitting the gaussian model\n",
        "###  when we fit the model, we need some loss function to optimize to find the parameters, is'nt it"
      ],
      "metadata": {
        "id": "rKyjRZ93Njhm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### My model should have 2 functionalities:\n",
        "1. inference ability (done temporarily)\n",
        "2. generation ability"
      ],
      "metadata": {
        "id": "xv_hzQBrDbKw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### EM algorithm for training the params for the GMM"
      ],
      "metadata": {
        "id": "Az3CW5-AQsdS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.core.formatters import Dict\n",
        "def EM_training(mean:np.array,mixing_coeffs:np.array,covs:Dict, dataset_input:np.array):\n",
        "  '''\n",
        "  Args:\n",
        "  mean=\n",
        "        shape(mean)= (L X dimension_of_the_problem_instance (whether 1D, 2D, 3D and so on))\n",
        "  mixing_coeffs=\n",
        "        shape(mixing_coeffs)= (1 X L)\n",
        "  covs= dict of covariance matrices.\n",
        "        shape(covs)= L number of entries, one for each of the P_l(x)\n",
        "  dataset_input: shape would be (num of data set X dimn_of_the_prob)\n",
        "  '''\n",
        "  L=np.shape(mean)[0]\n",
        "  dimn_of_prob=np.shape(dataset_input)[1]\n",
        "  # define gamma: responsibility\n",
        "  num_data=np.shape(dataset_input)[0] ### note shape(dataset_input)=(num data X dimn_of_the_problem)\n",
        "  gamma=np.zeros(shape=(num_data,L))\n",
        "  num_iters=1 # denoted as T in notes\n",
        "  ###\n",
        "  for t in range(0,num_iters):\n",
        "\n",
        "    ### evaluate the E step\n",
        "    # update the gamma.\n",
        "    for idx_over_data in range(0,num_data):\n",
        "      ### here i need to evaluate the common denominator that will go inside the next loop\n",
        "      # print(\"covs[idx_el]\")\n",
        "      # print(covs[0])\n",
        "      prod_mixing_coeffs_and_gaussian_l=[mixing_coeffs[0,idx_el]*gaussian_2d(x=dataset_input[idx_over_data,:].reshape((1,dimn_of_prob)),mean=mean[idx_el,:].reshape((1,dimn_of_prob)),cov_mat=covs[idx_el]) for idx_el in range(0,L)]\n",
        "      # print(\"pil_Pl_fordfnwnf:\")\n",
        "      # print(prod_mixing_coeffs_and_gaussian_l)\n",
        "      Dr_for_gamma=np.sum(prod_mixing_coeffs_and_gaussian_l)\n",
        "      gamma[idx_over_data,:]=[prod_mixing_coeffs_and_gaussian_l[k]/Dr_for_gamma for k in range(0,L)]\n",
        "\n",
        "    print(\"gamma obtained:\");print(gamma)\n",
        "    ### M-step: Re-estimating the parameters\n",
        "    N_l=np.sum(gamma,axis=0)# this is the expression sum_{i=1}^{N(all dataset)} gamma_{il} in the lecture notes\n",
        "    print(\"N_l is:\");print(N_l)# NOTE:: shape of N_l = (L,) (note that this array is 1D)\n",
        "\n",
        "    ### 1. updating means: the expresion is like a wtd sum of the vectors\n",
        "    ###\n",
        "    for idx_el in range(0,L):\n",
        "      #print(\"index el is:\");print(idx_el)\n",
        "      temp_vec=np.array(\n",
        "          [gamma[idx_over_data,idx_el]*dataset_input[idx_over_data,:]\n",
        "           for idx_over_data in range(0,num_data)]\n",
        "          )\n",
        "      #print(\"temp vec is:\");print(temp_vec)\n",
        "      #update the mean\n",
        "      # print(\"np.sum(temp_vec,axis=0):\",np.sum(temp_vec,axis=0))\n",
        "      # print(\"mean[idx_el,:]=\",mean[idx_el,:])\n",
        "      mean[idx_el,:]=(1./N_l[idx_el])*np.sum(temp_vec,axis=0)\n",
        "    print(\"mean matrix after update:\");print(mean)\n",
        "\n",
        "    ### 2. update the covariance matrix:\n",
        "    ##### formula for updating the cov mat is:\n",
        "    ##### sigma_lth=1/N_l[idx_el] * sum_{i=1}^{N(all_dataset)} * gamma_{il}*some_outer_product\n",
        "    for idx_el in range(0,L):\n",
        "      #print(\"updating cov matrix, index el is:\",idx_el)\n",
        "      temp_outer_prod_list=np.array(\n",
        "          [gamma[idx_over_data,idx_el]*(dataset_input[idx_over_data,:]-mean[idx_el,:]).reshape((dimn_of_prob,1)) @\n",
        "           (dataset_input[idx_over_data,:]-mean[idx_el,:]).reshape((1,dimn_of_prob))\n",
        "          for idx_over_data in range(0,num_data)\n",
        "         ]\n",
        "          )\n",
        "      #print(\"temp outer prodcut list is:\");print(temp_outer_prod_list)\n",
        "      #print(\"summed over:\");print(sum(temp_outer_prod_list))\n",
        "      covs[idx_el]=(1./N_l[idx_el])*sum(temp_outer_prod_list)\n",
        "    print(\"updated covriances\");print(covs)\n",
        "\n",
        "    ### 3. update the mixing coeffs:\n",
        "    for idx_el in range(0,L):\n",
        "      mixing_coeffs[0,idx_el]=N_l[idx_el]/num_data\n",
        "    print(\"updated mixing_coeffs:\");print(mixing_coeffs)\n",
        "\n",
        "    return mean,covs,mixing_coeffs"
      ],
      "metadata": {
        "id": "NeuVPY6hQx-H"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# an example to check whether the function EM_training working or not.\n",
        "# L=4, N=3, dim_of_prob=2\n",
        "mean=np.array([[1.5,1.25],[0.75,1.25],[1.3,1.7],[1.4,1.63]])\n",
        "print(\"mean:\");print(mean)\n",
        "mixing_coeffs=np.array([[0.25,0.25,0.25,0.25]])\n",
        "covs={0:np.array([[0.02,0.003],[0.003,0.1]]),\n",
        "      1: np.array([[0.06,0.007],[0.007,0.05]]),\n",
        "      2:np.array([[0.068,0.003],[0.007,0.05]]),\n",
        "      3:np.array([[0.06,0.007],[0.017,0.078]])}\n",
        "dataset_input=np.array([[1.78,1],[1.75,1.3],[1.03,1.08]])\n",
        "checking_em=EM_training(mean=mean,\n",
        "                        mixing_coeffs=mixing_coeffs,\n",
        "                        covs=covs,\n",
        "                        dataset_input=dataset_input)"
      ],
      "metadata": {
        "id": "aUW3xhLmp_fK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# a=np.array([[10,20],[1,2],[111,5]])\n",
        "# np.sum(a,axis=0),np.sum(a,axis=1)"
      ],
      "metadata": {
        "id": "7gzHwxQG2WUi"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implementation of MMD metric:\n",
        "\n",
        "a good resource for MMD: https://www.onurtunali.com/ml/2019/03/08/maximum-mean-discrepancy-in-machine-learning.html\n",
        "\n",
        "(implemented using pytorch)"
      ],
      "metadata": {
        "id": "jUiuhqZxR6nJ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YXEELMrQR4ch"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}