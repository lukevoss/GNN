{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Simple Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pip installs for Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch\n",
    "!pip install lightning\n",
    "!pip install matplotlib\n",
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import lightning as L\n",
    "\n",
    "from datasets import CustomMNIST\n",
    "from autoencoder import AutoencoderSimple\n",
    "from utils import plot_mnist_samples, plot_reconstruction_comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data and costruct dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomMNIST(root=\"./datasets\", train=True)\n",
    "test_dataset = CustomMNIST(root=\"./datasets\", train=False)\n",
    "\n",
    "# Define the sizes for train, validation, and test sets\n",
    "TRAIN_SIZE = int(0.8 * len(train_dataset))\n",
    "VAL_SIZE = len(train_dataset) - TRAIN_SIZE\n",
    "TEST_SIZE = len(test_dataset)\n",
    "BATCH_SIZE = 100\n",
    "\n",
    "train_data, val_data = torch.utils.data.random_split(\n",
    "    train_dataset, [TRAIN_SIZE, VAL_SIZE]\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot some sample images and labels from the dataset \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_images = [train_dataset[i][0].squeeze().numpy() for i in range(8)]\n",
    "sample_labels = [train_dataset[i][1] for i in range(8)]\n",
    "sample_captions = [f\"Label: {label}\" for label in sample_labels]\n",
    "plot_mnist_samples(sample_images, sample_labels, sample_captions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = AutoencoderSimple()\n",
    "\n",
    "# Initialize a trainer\n",
    "trainer = L.Trainer(max_epochs=100, progress_bar_refresh_rate=20, gpus=1 if torch.cuda.is_available() else 0)\n",
    "\n",
    "# Train the model\n",
    "trainer.fit(autoencoder, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_autoencoder(autoencoder, test_loader, device=\"cuda\" if torch.cuda.is_available() else \"cpu\"):\n",
    "    \"\"\"\n",
    "    Tests the autoencoder on a batch from the test_loader and plots original and reconstructed images.\n",
    "    :param autoencoder: The autoencoder model.\n",
    "    :param test_loader: DataLoader for the test dataset.\n",
    "    :param device: The device to run the model on.\n",
    "    \"\"\"\n",
    "    autoencoder.eval()\n",
    "    \n",
    "    # Get a batch of test images\n",
    "    images, _ = next(iter(test_loader))\n",
    "    images = images.to(device)\n",
    "    \n",
    "    # Reconstruct images using the autoencoder\n",
    "    with torch.no_grad():\n",
    "        reconstructed_images = autoencoder(images)\n",
    "    \n",
    "    # Prepare images for display\n",
    "    original_images = images.cpu()\n",
    "    reconstructed_images = reconstructed_images.cpu()\n",
    "    \n",
    "    # Plot original and reconstructed images\n",
    "    plot_reconstruction_comparison(original_images, reconstructed_images)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
