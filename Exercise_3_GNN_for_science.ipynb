{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/neelkanthrawat/GNN-exercises/blob/main/Exercise_3_GNN_for_science.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vaCGwnWuEEiS"
      },
      "source": [
        "# 1. Two moons with an invertible Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "n2OkMdaoDkic"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import make_moons\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "5rc9IryVX_SB"
      },
      "outputs": [],
      "source": [
        "### modified coupling layer class\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class CouplingLayer(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(CouplingLayer, self).__init__()\n",
        "        # Neural networks for the first half of the dimensions\n",
        "        self.fc1 = nn.Linear(input_size // 2, hidden_size)\n",
        "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
        "        # Translation coefficient\n",
        "        self.fc3 = nn.Linear(hidden_size, input_size // 2)\n",
        "        # Scaling coefficient\n",
        "        self.fc4 = nn.Linear(hidden_size, input_size // 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        #print(\"___ inside the coupling layer's forward function____\")\n",
        "        #print(\"x is:\"); print(x)\n",
        "        #print(\"shape of x is:\",x.shape)\n",
        "        # Split the input into two halves\n",
        "        x_a, x_b = x.chunk(2, dim=1)\n",
        "        #print(\"shape x_a is:\",x_a.shape)\n",
        "        #print(\"shape x_b is:\",x_b.shape)\n",
        "\n",
        "        # Apply neural network to calculate coefficients\n",
        "        h = F.relu(self.fc1(x_a))\n",
        "        h = F.relu(self.fc2(h))\n",
        "        translation = self.fc3(h)\n",
        "        scaling_before_exp = self.fc4(h)\n",
        "        scaling = torch.exp(torch.tanh(scaling_before_exp))\n",
        "\n",
        "        # Apply the affine transformation\n",
        "        y_b = x_b * scaling + translation\n",
        "\n",
        "        # Concatenate the transformed halves\n",
        "        y = torch.cat([x_a, y_b], dim=1)\n",
        "        #print(\" shape of y is (tensor after the coupling layer):\");print(y.shape)\n",
        "        return y, scaling_before_exp\n",
        "\n",
        "    def backward(self, y):\n",
        "        # Split the input into two halves\n",
        "        y_a, y_b = y.chunk(2, dim=1)\n",
        "\n",
        "        # Apply neural network to calculate coefficients (reverse)\n",
        "        h = F.relu(self.fc1(y_a))\n",
        "        h = F.relu(self.fc2(h))\n",
        "        translation = self.fc3(h)\n",
        "        scaling_before_exp = self.fc4(h)\n",
        "        scaling = torch.exp(torch.tanh(scaling_before_exp))\n",
        "\n",
        "        # Reverse the operations to reconstruct the original input\n",
        "        x_a = y_a\n",
        "        x_b = (y_b - translation) / scaling\n",
        "\n",
        "        # Concatenate the reconstructed halves\n",
        "        x = torch.cat([x_a, x_b], dim=1)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "d5Lq0vtfcNrp"
      },
      "outputs": [],
      "source": [
        "class RealNVP(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, blocks):\n",
        "        super(RealNVP, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.blocks = blocks\n",
        "\n",
        "        # List of coupling layers\n",
        "        self.coupling_layers = nn.ModuleList([\n",
        "            CouplingLayer(input_size, hidden_size) for _ in range(blocks)\n",
        "        ])\n",
        "        #print(\"self.input size is:\",self.input_size)\n",
        "\n",
        "\n",
        "        # List to store orthonormal matrices\n",
        "        self.orthonormal_matrices = [self._get_orthonormal_matrix(input_size) for _ in range(blocks)]\n",
        "        # print(\"set of orthogonal matrixes are\")\n",
        "        # print(self.orthonormal_matrices)\n",
        "        # print(\"some test check: \"); print(type(self.orthonormal_matrices[0]))\n",
        "        # print(\"shape is:\");print(self.orthonormal_matrices)\n",
        "\n",
        "        # List to store scaling_before_exp for each block\n",
        "        self.scaling_before_exp_list = []\n",
        "\n",
        "    def _get_orthonormal_matrix(self, size):\n",
        "        # Function to generate a random orthonormal matrix\n",
        "        w = torch.randn(size, size)\n",
        "        q, _ = torch.linalg.qr(w,'reduced')\n",
        "        return q\n",
        "\n",
        "    def forward_realnvp(self, x):\n",
        "        #print(\"inside the forward_realnvp function\")\n",
        "        scaling_before_exp_list = []\n",
        "        for i in range(self.blocks):\n",
        "            #print(\"type of (self.orthonormal_matrices[0]):\",type(self.orthonormal_matrices[0]))\n",
        "            #print(\"x is:\");print(x)\n",
        "            #print(\"self.orthonormal_matrices[i]:\");print(self.orthonormal_matrices[i])\n",
        "\n",
        "            # Apply random orthonormal matrix\n",
        "            x = torch.matmul(x, self.orthonormal_matrices[i])\n",
        "\n",
        "            # Apply coupling layer\n",
        "            x, scaling_before_exp = self.coupling_layers[i].forward(x)\n",
        "            scaling_before_exp_list.append(scaling_before_exp)\n",
        "\n",
        "        self.scaling_before_exp_list = scaling_before_exp_list\n",
        "        return x\n",
        "\n",
        "    def encode(self, x):\n",
        "        # Encoding is the forward pass through the RealNVP model\n",
        "        return self.forward_realnvp(x)\n",
        "\n",
        "    def decode(self, z):\n",
        "        # Reverse transformations for decoding\n",
        "        for i in reversed(range(self.blocks)):\n",
        "            # Apply random orthonormal matrix (reverse)\n",
        "            z = z @ self.orthonormal_matrices[i].t()\n",
        "            # Apply coupling layer (reverse)\n",
        "            z = self.coupling_layers[i].backward(z)\n",
        "        return z"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "o_V22geTZkcz"
      },
      "outputs": [],
      "source": [
        "### defining our loss function\n",
        "def calculate_loss(transformed_x, scaling_before_exp_list, dataset_length):\n",
        "    \"\"\"\n",
        "    Calculate the loss for the RealNVP model.\n",
        "\n",
        "    Args:\n",
        "    - transformed_x (tensor): Transformed data produced by the RealNVP model.\n",
        "    - scaling_before_exp_list (list): List of scaling_before_exp values for each block.\n",
        "    - dataset_length (int): The length of the dataset.\n",
        "\n",
        "    Returns:\n",
        "    - loss (tensor): The calculated loss value.\n",
        "    \"\"\"\n",
        "    #print(\"******************inside the calculate loss function**************\")\n",
        "    #print(\"transformed x's shape is:\", transformed_x.shape)\n",
        "    #print(\"scaling_before_exp_list is:\", scaling_before_exp_list)\n",
        "\n",
        "    # Calculate the first term of the loss (negative log-likelihood term)\n",
        "    first_term = torch.sum(transformed_x**2) / 2\n",
        "\n",
        "    # Calculate the second term of the loss (sum over scaling_before_exp values)\n",
        "    second_term = 0.0\n",
        "    for scaling_before_exp in scaling_before_exp_list:\n",
        "        second_term -= scaling_before_exp.sum()\n",
        "\n",
        "    # Calculate the total loss\n",
        "    loss = (first_term + second_term) / dataset_length\n",
        "\n",
        "    return abs(loss)#### if i return the absolute value of this loss, then I observed improvement! so IDK!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_loss(z, scaling_before_exp_list, dummy):\n",
        "    # Compute the negative log-likelihood loss\n",
        "    log_likelihoods = 0.5 * torch.sum(z**2, dim=1)  # Assuming a standard Gaussian prior\n",
        "    for scaling_before_exp in scaling_before_exp_list:\n",
        "        log_likelihoods += torch.sum(torch.log(torch.abs(scaling_before_exp)), dim=1)\n",
        "    return -torch.mean(log_likelihoods)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "M1nqAXuofj15"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "def train_and_evaluate(model, train_loader, val_loader, num_epochs=10, lr=0.001, print_after=1):\n",
        "    \"\"\"\n",
        "    Train the RealNVP model and evaluate on a validation dataset.\n",
        "\n",
        "    Args:\n",
        "    - model (RealNVP): The RealNVP model to be trained.\n",
        "    - train_loader (DataLoader): DataLoader for the training dataset.\n",
        "    - val_loader (DataLoader): DataLoader for the validation dataset.\n",
        "    - num_epochs (int): Number of training epochs.\n",
        "    - lr (float): Learning rate for the optimizer.\n",
        "    - print_after (int): Number of epochs after which to print the training and validation loss.\n",
        "\n",
        "    Returns:\n",
        "    - train_losses (list): List of training losses for each epoch.\n",
        "    - val_losses (list): List of validation losses for each epoch.\n",
        "    \"\"\"\n",
        "\n",
        "    # Define the optimizer\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    train_losses = []  # List to store training losses\n",
        "    val_losses = []    # List to store validation losses\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        total_train_loss = 0.0\n",
        "\n",
        "        # Training phase\n",
        "        model.train()  # Set the model to training mode\n",
        "        for data in train_loader:\n",
        "            inputs= data\n",
        "\n",
        "            # Zero the gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass (encoding)\n",
        "            encoded = model.encode(inputs)\n",
        "\n",
        "            # Loss calculation\n",
        "            train_loss = calculate_loss(encoded, model.scaling_before_exp_list, len(train_loader))\n",
        "\n",
        "            # Backward pass (gradient computation)\n",
        "            train_loss.backward()\n",
        "\n",
        "            # Update weights\n",
        "            optimizer.step()\n",
        "\n",
        "            total_train_loss += train_loss.item()\n",
        "\n",
        "        # Average training loss for the epoch\n",
        "        average_train_loss = total_train_loss / len(train_loader)\n",
        "\n",
        "        # Validation phase\n",
        "        if val_loader is not None:\n",
        "            model.eval()  # Set the model to evaluation mode\n",
        "            total_val_loss = 0.0\n",
        "            with torch.no_grad():\n",
        "                for val_data in val_loader:\n",
        "                    val_inputs = val_data\n",
        "\n",
        "                    # Forward pass (encoding) for validation\n",
        "                    val_encoded = model.encode(val_inputs)\n",
        "\n",
        "                    # Loss calculation for validation\n",
        "                    val_loss = calculate_loss(val_encoded, model.scaling_before_exp_list, len(val_loader))\n",
        "\n",
        "                    total_val_loss += val_loss.item()\n",
        "\n",
        "            # Average validation loss for the epoch\n",
        "            average_val_loss = total_val_loss / len(val_loader)\n",
        "\n",
        "            # Print training and validation losses together\n",
        "            if (epoch + 1) % print_after == 0:\n",
        "                print(f\"Epoch {epoch + 1}/{num_epochs}, Training Loss: {average_train_loss}, Validation Loss: {average_val_loss}\")\n",
        "\n",
        "            # Append losses to the lists\n",
        "            train_losses.append(average_train_loss)\n",
        "            val_losses.append(average_val_loss)\n",
        "\n",
        "        # Set the model back to training mode\n",
        "        model.train()\n",
        "\n",
        "    print(\"Training complete\")\n",
        "\n",
        "    return train_losses, val_losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "UmgEQmpLjoPN"
      },
      "outputs": [],
      "source": [
        "dataset_sizes = [ 500, 1000, 5000]\n",
        "\n",
        "# Generate datasets of varying sizes\n",
        "train_datasets = {}\n",
        "val_datasets = {}\n",
        "datasets = {}\n",
        "\n",
        "for size in dataset_sizes:\n",
        "    X, y = make_moons(n_samples=size, noise=0.1)\n",
        "    datasets[size] = {'X': X, 'y': y}\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "    train_datasets[size] = {'X': torch.FloatTensor(X_train), 'y': y_train}\n",
        "    val_datasets[size] = {'X': torch.FloatTensor(X_test), 'y': y_test}\n",
        "\n",
        "# # Visualize the training datasets\n",
        "# plt.figure(figsize=(12, 8))\n",
        "\n",
        "# for i, size in enumerate(dataset_sizes, 1):\n",
        "#     plt.subplot(2, 2, i)\n",
        "#     plt.scatter(datasets[size]['X'][:, 0], datasets[size]['X'][:, 1], c=datasets[size]['y'])\n",
        "#     plt.title(f'Dataset Size: {size}')\n",
        "\n",
        "# plt.show() \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "iZprf1n5iml3"
      },
      "outputs": [],
      "source": [
        "### creating the dataloader for the make moons dataset\n",
        "from torch.utils.data import DataLoader, TensorDataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "DZKxq2cykCV1",
        "outputId": "a721163c-5823-4c6a-cfb4-37d46b11bf78"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "shape of the data_considered\n",
            "torch.Size([700, 2])\n",
            "Epoch 10/100, Training Loss: -2.1914996853108665e+23, Validation Loss: -2.2527835079302567e+23\n",
            "Epoch 20/100, Training Loss: -2.2732065527082284e+23, Validation Loss: -2.3814915754361036e+23\n",
            "Epoch 30/100, Training Loss: -2.321072201569625e+23, Validation Loss: -2.4265678879336726e+23\n",
            "Epoch 40/100, Training Loss: -2.3449221515788167e+23, Validation Loss: -2.504497905669714e+23\n",
            "Epoch 50/100, Training Loss: -2.362940267605082e+23, Validation Loss: -2.4870778201814586e+23\n",
            "Epoch 60/100, Training Loss: -2.3722667311315886e+23, Validation Loss: -2.5736054077645338e+23\n",
            "Epoch 70/100, Training Loss: -2.3742278768136866e+23, Validation Loss: -2.5075204154948305e+23\n",
            "Epoch 80/100, Training Loss: -2.3826258454875626e+23, Validation Loss: -2.5317113387636645e+23\n",
            "Epoch 90/100, Training Loss: -2.3878152368894634e+23, Validation Loss: -2.5317679760325784e+23\n",
            "Epoch 100/100, Training Loss: -2.3921946599925628e+23, Validation Loss: -2.5257834307181418e+23\n",
            "Training complete\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\luke\\AppData\\Local\\Temp\\ipykernel_26228\\1200463455.py:35: UserWarning: Data has no positive values, and therefore cannot be log-scaled.\n",
            "  plt.yscale('log')\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "### Trial run\n",
        "input_size=2\n",
        "hidden_size=128\n",
        "blocks=6\n",
        "print_after=1\n",
        "\n",
        "\n",
        "\n",
        "#### data for the two-moons model\n",
        "dataset_size=1000\n",
        "batch_size=32\n",
        "data_considered=train_datasets[dataset_size]['X']\n",
        "print(\"shape of the data_considered\"); print(data_considered.shape)\n",
        "train_loader = torch.utils.data.DataLoader(data_considered, batch_size=32, shuffle=True)\n",
        "val_loader= torch.utils.data.DataLoader(val_datasets[dataset_size]['X'], batch_size=32, shuffle=True)\n",
        "####\n",
        "\n",
        "### instantiate the model\n",
        "model= RealNVP(input_size=2, hidden_size= hidden_size, blocks=blocks)\n",
        "\n",
        "## train the model\n",
        "train_losses, val_losses= train_and_evaluate(model, train_loader, val_loader, num_epochs=100, lr=0.004, print_after=10)\n",
        "#train_inn(model, train_loader, num_epochs=500, lr=0.01, print_after=10)\n",
        "\n",
        "\n",
        "# plotting the loss\n",
        "plt.plot(train_losses,label=\"train_loss\")\n",
        "plt.plot(val_losses, label= \"validation loss\")\n",
        "plt.show()\n",
        "\n",
        "### log plot\n",
        "plt.figure()\n",
        "plt.plot(train_losses,label=\"train_loss\")\n",
        "plt.plot(val_losses, label= \"validation loss\")\n",
        "plt.yscale('log')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J6jOeVqWBggq"
      },
      "source": [
        "### Tasks to do atm:\n",
        "\n",
        "1. check if the model is implemented correctly.\n",
        "2. MOST IMPORTANTLY: is the loss function implemented correctly? when I return the abs(loss) in the `calculate_loss` function, I see some training and improvement. IDK whether the loss function I have implemented is correct or not!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "JwgoNzNn7VJk"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pf6CdptMD93x"
      },
      "source": [
        "### Everything below is garbage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "aGYI6TJig10f"
      },
      "outputs": [],
      "source": [
        "# seperate functions for training and validation.\n",
        "# import torch.optim as optim\n",
        "# def train_inn(model, train_loader, num_epochs=10, lr=0.001, print_after=10):\n",
        "#     \"\"\"\n",
        "#     Train the RealNVP model.\n",
        "\n",
        "#     Args:\n",
        "#     - model (RealNVP): The RealNVP model to be trained.\n",
        "#     - train_loader (DataLoader): DataLoader for the training dataset.\n",
        "#     - num_epochs (int): Number of training epochs.\n",
        "#     - lr (float): Learning rate for the optimizer.\n",
        "#     - print_after (int): Number of epochs after which to print the training loss.\n",
        "\n",
        "#     Returns:\n",
        "#     - train_losses (list): List of training losses for each epoch.\n",
        "#     \"\"\"\n",
        "\n",
        "#     # Define the optimizer\n",
        "#     optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "#     train_losses = []  # List to store training losses\n",
        "\n",
        "#     for epoch in range(num_epochs):\n",
        "#         total_train_loss = 0.0\n",
        "\n",
        "#         # Training phase\n",
        "#         model.train()  # Set the model to training mode\n",
        "#         for data in train_loader:\n",
        "#             inputs = data#[0] # there is something here which I really need to look into\n",
        "#             #print(\"data from train_loader is inputs is:\"); print(inputs)\n",
        "\n",
        "#             # Zero the gradients\n",
        "#             optimizer.zero_grad()\n",
        "\n",
        "#             # Forward pass (encoding)\n",
        "#             encoded = model.encode(inputs)\n",
        "\n",
        "#             # Loss calculation\n",
        "#             train_loss = calculate_loss(encoded, model.scaling_before_exp_list, len(train_loader))\n",
        "\n",
        "#             # Backward pass (gradient computation)\n",
        "#             train_loss.backward()\n",
        "\n",
        "#             # Update weights\n",
        "#             optimizer.step()\n",
        "\n",
        "#             total_train_loss += train_loss.item()\n",
        "\n",
        "#         # Average training loss for the epoch\n",
        "#         average_train_loss = total_train_loss / len(train_loader)\n",
        "\n",
        "#         # Print training loss after specified number of epochs\n",
        "#         if (epoch + 1) % print_after == 0:\n",
        "#             print(f\"Epoch {epoch + 1}/{num_epochs}, Training Loss: {average_train_loss}\")\n",
        "\n",
        "#         # Append losses to the list\n",
        "#         train_losses.append(average_train_loss)\n",
        "\n",
        "#     print(\"Training complete\")\n",
        "\n",
        "#     return train_losses\n",
        "\n",
        "\n",
        "# def validate_inn(model, val_loader,  print_after=10):\n",
        "#     \"\"\"\n",
        "#     Validate the RealNVP model.\n",
        "\n",
        "#     Args:\n",
        "#     - model (RealNVP): The RealNVP model to be validated.\n",
        "#     - val_loader (DataLoader): DataLoader for the validation dataset.\n",
        "#     - print_after (int): Number of epochs after which to print the validation loss.\n",
        "\n",
        "#     Returns:\n",
        "#     - val_losses (list): List of validation losses for each epoch.\n",
        "#     \"\"\"\n",
        "\n",
        "#     val_losses = []  # List to store validation losses\n",
        "\n",
        "#     model.eval()  # Set the model to evaluation mode\n",
        "#     total_val_loss = 0.0\n",
        "\n",
        "#     with torch.no_grad():\n",
        "#         for epoch, val_data in enumerate(val_loader, 1):\n",
        "#             val_inputs = val_data\n",
        "\n",
        "#             # Forward pass (encoding) for validation\n",
        "#             val_encoded = model.encode(val_inputs)\n",
        "\n",
        "#             # Loss calculation for validation\n",
        "#             val_loss = calculate_loss(val_encoded, model.scaling_before_exp_list, len(val_loader))\n",
        "\n",
        "#             total_val_loss += val_loss.item()\n",
        "\n",
        "#             # Print validation loss after specified number of epochs\n",
        "#             if epoch % print_after == 0:\n",
        "#                 average_val_loss = total_val_loss / epoch\n",
        "#                 print(f\"Epoch {epoch}/{len(val_loader)}, Validation Loss: {average_val_loss}\")\n",
        "\n",
        "#                 # Append average validation loss to the list\n",
        "#                 val_losses.append(average_val_loss)\n",
        "\n",
        "#     print(\"Validation complete\")\n",
        "\n",
        "#     return val_losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "7kHbOvSbm-XT"
      },
      "outputs": [],
      "source": [
        "# import torch\n",
        "\n",
        "\n",
        "# # Example data\n",
        "# data_size = 500\n",
        "# input_size = 2\n",
        "# hidden_size = 256\n",
        "# blocks = 3\n",
        "# print_after = 10\n",
        "\n",
        "# # Create a dummy dataset\n",
        "# X = torch.randn(data_size, input_size)\n",
        "# print(\"shape of the dataset is:\"); print(X.shape)\n",
        "# print(\"X is :\"); print(X)\n",
        "\n",
        "# # Create a DataLoader for the dataset\n",
        "# train_dataset = TensorDataset(X)\n",
        "# train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "# # Initialize the RealNVP model\n",
        "# model2 = RealNVP(input_size, hidden_size, blocks)\n",
        "\n",
        "# # Train the model\n",
        "# train_losses = train_inn(model2, train_loader, num_epochs=1, lr=0.001, print_after=1)\n",
        "\n",
        "# ## Print the final training and validation losses\n",
        "# #print(f\"Final Training Loss: {train_losses[-1]}, Final Validation Loss: {val_losses[-1]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "0IscDqh0nSW6"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyPSgzwzeqyn49kmK7+aZMLS",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
